{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this code, make sure you have <br>\n",
    "1) images/  folder which as all the images (raw data; unzipped from the tar file) <br>\n",
    "2) images/train_val_filtered.pkl : list of non blacklisted training images <br>\n",
    "3) images/test_filtered.pkl : list of non blacklisted test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'],\n",
       "          sparse_output=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_labels =['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',\n",
    "                 'Fibrosis','Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening',\n",
    "                 'Pneumonia','Pneumothorax']\n",
    "    \n",
    "## convert to Multilabels \n",
    "mlb = MultiLabelBinarizer(classes=set_labels)\n",
    "mlb.fit(set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2vector(label):\n",
    "    \n",
    "    ## INPUT : ['Atelectasis', 'Cardiomegaly']\n",
    "    ## OUTPUT : [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    label = [label]\n",
    "    test_labels_str = [i.split('|') for i in label]\n",
    "    test_labels_str = [ x if 'Finding' not in x[0] else [] for x in (test_labels_str)]\n",
    "    return mlb.transform(test_labels_str)[0]\n",
    "\n",
    "def get_vector_labels(path, is_test):\n",
    "    \n",
    "    ## INPUT : ('../data/images/, True)\n",
    "    ## OUTPUT : \n",
    "    \n",
    "#         img_filename\t             vector\n",
    "# 44187   00013774_026.png    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "# 44188   00013774_028.png    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "    \n",
    "    \n",
    "    ## read list of non-blacklisted images; train and test \n",
    "    if not is_test:\n",
    "        train_img_list = pd.read_pickle(path + \"train_val_filtered.pkl\")\n",
    "    else:\n",
    "        train_img_list = pd.read_pickle(path + \"test_filtered.pkl\")\n",
    "        \n",
    "    ## read images in our images folder \n",
    "    single_tar_images = [i.split('/')[1] for i in glob.glob(path + '*.png')]\n",
    "    ## subset \n",
    "    train_img_list = train_img_list[train_img_list['img_filename'].isin(single_tar_images)]\n",
    "    \n",
    "    train_img_list['vector'] = train_img_list['text_label'].apply(label2vector)\n",
    "    train_img_list = train_img_list[['img_filename', 'vector']]\n",
    "    return train_img_list\n",
    "\n",
    "def train_val_splitter(train_df, percentage = 0.1):\n",
    "    \n",
    "    assert percentage <= 1\n",
    "    assert percentage > 0\n",
    "    \n",
    "    ## INPUT :  training_df of the shape (n,2), 0 <float <=1\n",
    "    ## OUTPUT : validation_df, train_df; no patient overlap in the two dfs\n",
    "                # validation_Df.shape = ~(n*percentage,2), \n",
    "                # train_df.shape = ~(n*(1-percentage), 2)\n",
    "    \n",
    "    col_list = train_df.columns.tolist()\n",
    "    \n",
    "    train_df['patient'] = train_df.img_filename.apply(lambda x : x.split(\"_\")[0])\n",
    "    valid_patients = np.random.choice(train_df.patient.unique(), \n",
    "                 int(train_df.patient.unique().shape[0]*percentage),\n",
    "                 replace=False)\n",
    "    \n",
    "    valid_df = train_df[train_df['patient'].isin(valid_patients)]\n",
    "    dummy = train_df[~train_df['patient'].isin(valid_patients)]\n",
    "    \n",
    "    # assert no rows are missed \n",
    "    assert valid_df.shape[0] + dummy.shape[0] == train_df.shape[0]\n",
    "    # assert intersection is null\n",
    "    assert np.intersect1d(valid_df.patient.values, dummy.patient.values).tolist() == []\n",
    "    \n",
    "    return valid_df[col_list], dummy[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8412, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_vector_labels(path = 'images/', is_test = False)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1469, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = get_vector_labels(path = 'images/', is_test = True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(859, 2) (7553, 2) (1469, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df, train_df = train_val_splitter(train_df, 0.1)\n",
    "print (valid_df.shape, train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_filename</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20744</th>\n",
       "      <td>00006587_000.png</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20745</th>\n",
       "      <td>00006588_000.png</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20746</th>\n",
       "      <td>00006588_001.png</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20747</th>\n",
       "      <td>00006588_002.png</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20748</th>\n",
       "      <td>00006588_003.png</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_filename                                      vector\n",
       "20744  00006587_000.png  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "20745  00006588_000.png  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
       "20746  00006588_001.png  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "20747  00006588_002.png  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "20748  00006588_003.png  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 14\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "LR = 0.0001\n",
    "EPOCHS = 2 #100\n",
    "# Can scale to max for inference but for training LR will be affected\n",
    "# Prob better to increase this though on P100 since LR is not too low\n",
    "# Easier to see when plotted\n",
    "BATCHSIZE = 16 #64*2\n",
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_SD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  3 19:38:29 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   38C    P0    29W / 300W |     10MiB / 16152MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "CUDA Version 8.0.61\n",
      "CUDA Version 9.0.176\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!cat /usr/local/cuda-8.0/version.txt\n",
    "!cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_df, root_dir, transform=None):\n",
    "        self.df = train_df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        labels = torch.FloatTensor(train_df[train_df['img_filename'] == train_df.iloc[idx, 0]]['vector'].values[0])\n",
    "        #labels = torch.FloatTensor(np.array([0]*14))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(IMAGENET_RGB_MEAN, IMAGENET_RGB_SD)\n",
    "\n",
    "train_dataset = XRayDataset(train_df,\n",
    "                                    root_dir= os.path.join(os.getcwd() + '/images/'), \n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize(WIDTH),\n",
    "                           transforms.ToTensor(),\n",
    "                           normalize]))\n",
    "\n",
    "test_dataset = XRayDataset(test_df,\n",
    "                                    root_dir= os.path.join(os.getcwd() + '/images/'), \n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize(WIDTH),\n",
    "                           transforms.ToTensor(),\n",
    "                           normalize]))\n",
    "\n",
    "valid_dataset = XRayDataset(valid_df,\n",
    "                                    root_dir= os.path.join(os.getcwd() + '/images/'), \n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize(WIDTH),\n",
    "                           transforms.ToTensor(),\n",
    "                           normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(out_features=CLASSES):\n",
    "    model = models.densenet.densenet121(pretrained=True)\n",
    "    # Replace classifier (FC-1000) with (FC-14)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(model.classifier.in_features, out_features), \n",
    "        nn.Sigmoid())\n",
    "    # CUDA\n",
    "    model.cuda()  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_symbol(sym, lr=LR):\n",
    "    # torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    opt = optim.Adam(sym.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = ReduceLROnPlateau(opt, factor = 0.1, patience = 5, mode = 'min')\n",
    "    return opt, criterion, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(data_gt, data_pd, mean=True, classes=CLASSES):\n",
    "    roc_auc = []\n",
    "    data_gt = data_gt.cpu().numpy()\n",
    "    data_pd = data_pd.cpu().numpy()\n",
    "    for i in range(classes):\n",
    "        roc_auc.append(roc_auc_score(data_gt[:, i], data_pd[:, i]))\n",
    "    if mean:\n",
    "        roc_auc = np.mean(roc_auc)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, epoch, batch=BATCHSIZE):\n",
    "    model.train()\n",
    "    print(\"Training epoch {}\".format(epoch+1))\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in tqdm(dataloader):\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda())\n",
    "        target = Variable(torch.FloatTensor(target).cuda())\n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "        # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Back-prop\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "         # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "    print(\"Training loss: {0:.4f}\".format(loss_val/loss_cnt))\n",
    "\n",
    "\n",
    "def valid_epoch(model, dataloader, criterion, epoch, phase='valid', batch=BATCHSIZE):\n",
    "    model.eval()\n",
    "    if phase == 'testing':\n",
    "        print(\"Testing epoch {}\".format(epoch+1))\n",
    "    else:\n",
    "        print(\"Validating epoch {}\".format(epoch+1))\n",
    "    out_pred = torch.FloatTensor().cuda()\n",
    "    out_gt = torch.FloatTensor().cuda()\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in dataloader:\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda(), volatile=True)\n",
    "        target = Variable(torch.FloatTensor(target).cuda(), volatile=True)\n",
    "         # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "        # Log for AUC\n",
    "        out_pred = torch.cat((out_pred, output.data), 0)\n",
    "        out_gt = torch.cat((out_gt, target.data), 0)\n",
    "    loss_mean = loss_val/loss_cnt\n",
    "    if phase == 'testing':\n",
    "        print(\"Test-Dataset loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Test-Dataset AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred)))\n",
    "\n",
    "    else:\n",
    "        print(\"Validation loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Validation AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred)))\n",
    "    return loss_mean\n",
    "\n",
    "def print_learning_rate(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        print(\"Learining rate: \", param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCHSIZE,\n",
    "                          shuffle=True, num_workers=0, pin_memory=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=8*BATCHSIZE,\n",
    "                          shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=8*BATCHSIZE,\n",
    "                         shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 492 ms, total: 3.11 s\n",
      "Wall time: 3.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "azure_chest_xray_sym = get_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load optimiser, loss\n",
    "optimizer, criterion, scheduler = init_symbol(azure_chest_xray_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/473 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7077\n",
      "Validation AUC: 0.5059\n",
      "Training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [03:38<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1684\n",
      "Validating epoch 1\n",
      "Validation loss: 0.1901\n",
      "Validation AUC: 0.5183\n",
      "Learining rate:  0.0001\n",
      "Loss decreased. Saving ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/473 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time: 265 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [03:37<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1278\n",
      "Validating epoch 2\n",
      "Validation loss: 0.2061\n",
      "Validation AUC: 0.5307\n",
      "Learining rate:  0.0001\n",
      "Epoch time: 506 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "loss_min = float(\"inf\")    \n",
    "\n",
    "# No-training\n",
    "valid_epoch(azure_chest_xray_sym, valid_loader, criterion, -1)\n",
    "\n",
    "# Main train/val/test loop\n",
    "for j in (range(EPOCHS)):\n",
    "    stime = time.time()\n",
    "    train_epoch(azure_chest_xray_sym, train_loader, optimizer, criterion, j)\n",
    "    loss_val = valid_epoch(azure_chest_xray_sym, valid_loader, criterion, j)\n",
    "#     test_loss_val = valid_epoch(azure_chest_xray_sym, test_loader, criterion, j, 'testing')\n",
    "    # LR Schedule\n",
    "    scheduler.step(loss_val)\n",
    "    print_learning_rate(optimizer)\n",
    "    # todo: tensorboard hooks\n",
    "    # Logging\n",
    "    if loss_val < loss_min:\n",
    "        print(\"Loss decreased. Saving ...\")\n",
    "        loss_min = loss_val\n",
    "        torch.save({'epoch': j + 1, \n",
    "                    'state_dict': azure_chest_xray_sym.state_dict(), \n",
    "                    'best_loss': loss_min, \n",
    "                    'optimizer' : optimizer.state_dict()}, 'best_azure_chest_xray_model_v2.pth.tar')\n",
    "    etime = time.time()\n",
    "    print(\"Epoch time: {0:.0f} seconds\".format(etime-stime))\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model for testing\n",
    "# azure_chest_xray_sym_test = get_symbol()\n",
    "# chkpt = torch.load(\"best_azure_chest_xray_model_v2.pth.tar\")\n",
    "# azure_chest_xray_sym_test.load_state_dict(chkpt['state_dict'])\n",
    "\n",
    "# valid_loss = valid_epoch(azure_chest_xray_sym_test, valid_loader, criterion, -1)\n",
    "# test_loss = valid_epoch(azure_chest_xray_sym_test, test_loader, criterion, -1, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
